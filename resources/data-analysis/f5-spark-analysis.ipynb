{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F5.news Trending News - Machine Learning Exploration\n",
    "\n",
    "- News Article Sentiment\n",
    "- Predict Trending Topics\n",
    "- Topic Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U \"pymongo[srv]\" mlflow pyspark hvac python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import hvac\n",
    "import mlflow\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Vault for Mongo connection values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "client = hvac.Client(\n",
    "    url=os.environ.get('VAULT_ADDR'),\n",
    "    token=os.environ.get('VAULT_TOKEN'),\n",
    ")\n",
    "\n",
    "print(client.is_authenticated())\n",
    "\n",
    "if client.is_authenticated():\n",
    "    try:\n",
    "        secret_resp = client.secrets.kv.v2.read_secret_version(\n",
    "            mount_point='kv', \n",
    "            path='f5.news', \n",
    "            raise_on_deleted_version=False\n",
    "        )\n",
    "        \n",
    "        if secret_resp['data'] is not None:\n",
    "            secret_values = secret_resp['data']['data']\n",
    "            for secret, value in secret_values.items():\n",
    "                os.environ[str(secret)] = str(value)\n",
    "        else:\n",
    "            print(\"The secret does not exist.\")\n",
    "    except hvac.exceptions.InvalidPath:\n",
    "        print(\"The path is invalid or the permission is denied.\")\n",
    "    except hvac.exceptions.Forbidden:\n",
    "        print(\"The permission is denied.\")\n",
    "    except hvac.exceptions.VaultError as e:\n",
    "        print(f\"Vault error occurred: {e}\")\n",
    "else:\n",
    "    print(\"Failed to connect to HashiVault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "URI = os.environ['mongo_uri']\n",
    "DATABASE = os.environ['database']\n",
    "COLLECTION = os.environ['collection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull F5 records using pymongo client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB\n",
      "Mongo documents loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a new client and connect to the server\n",
    "client = MongoClient(URI, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Successfully connected to MongoDB...\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    database = client[DATABASE]\n",
    "    collection = database[COLLECTION]\n",
    "\n",
    "    # Query all documents in the collection\n",
    "    documents = collection.find({\"sub\": \"politics\"}).sort({\"upvoteCount\": -1, \"fetchedAt\": -1})\n",
    "\n",
    "    if(DEBUG == True):\n",
    "        # Iterate over the cursor to access the documents\n",
    "        for doc in documents:\n",
    "            print(doc[\"title\"])\n",
    "            print(doc[\"fetchedAt\"])\n",
    "            print(doc[\"upvoteCount\"], \"upvotes\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"Mongo documents loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from MongoDB!\n",
      "root\n",
      " |-- __v: integer (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- commentCount: integer (nullable = true)\n",
      " |-- commentLink: string (nullable = true)\n",
      " |-- created_utc: integer (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- fetchedAt: timestamp (nullable = true)\n",
      " |-- is_self: boolean (nullable = true)\n",
      " |-- is_video: boolean (nullable = true)\n",
      " |-- media: struct (nullable = true)\n",
      " |    |-- event_id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- post_hint: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- selftext_html: string (nullable = true)\n",
      " |-- sub: string (nullable = true)\n",
      " |-- thumbnail: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- upvoteCount: integer (nullable = true)\n",
      " |-- upvote_ratio: double (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|__v|_id                       |author        |commentCount|commentLink                                                                 |created_utc|domain          |fetchedAt              |is_self|is_video|media|post_hint|selftext|selftext_html|sub |thumbnail|title                                                                                           |upvoteCount|upvote_ratio|url                                                                                                                                     |\n",
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |{65e0f6047e56c7a1e4ab5396}|nirad         |1066        |/r/news/comments/1b37ga3/donald_trump_found_to_have_fraudulently_boosted/   |1709231372 |thenational.scot|2024-03-01 23:44:19.914|false  |false   |NULL |NULL     |        |NULL         |news|         |Donald Trump found to have fraudulently boosted value of Scots homes by up to £200m             |21842      |0.91        |https://www.thenational.scot/news/24143657.donald-trump-found-fraudulently-boosted-value-scots-homes-200m/                              |\n",
      "|0  |{65e112247e56c7a1e4036388}|sue_me_please |170         |/r/news/comments/1b3effu/lgbtq_group_sues_to_block_texas_ag_paxtons/        |1709247994 |keranews.org    |2024-03-01 23:39:19.997|false  |false   |NULL |NULL     |        |NULL         |news|         |LGBTQ group sues to block Texas AG Paxton's request for records about transgender children      |4610       |0.93        |https://www.keranews.org/texas-news/2024-02-29/lgbtq-group-sues-to-block-texas-ag-paxtons-request-for-records-about-transgender-children|\n",
      "|0  |{65e12f707e56c7a1e45d8409}|BarKnight     |411         |/r/news/comments/1b3hbvu/michigan_communities_will_share_a_record_87m_in/   |1709255499 |freep.com       |2024-03-02 00:24:22.398|false  |false   |NULL |NULL     |        |NULL         |news|         |Michigan communities will share a record $87M in marijuana tax revenue                          |6265       |0.97        |https://www.freep.com/story/news/marijuana/2024/02/29/michigan-communities-will-share-a-record-87m-in-marijuana-tax-revenue/72792733007/|\n",
      "|0  |{65e158747e56c7a1e4d232f4}|Silent_killa42|1003        |/r/news/comments/1b3l1u6/irs_launches_crackdown_on_125000_wealthy_nonfilers/|1709266176 |apnews.com      |2024-03-02 14:34:20.029|false  |false   |NULL |NULL     |        |NULL         |news|         |IRS launches crackdown on 125,000 wealthy ‘non-filers’                                          |20920      |0.96        |https://apnews.com/article/irs-tax-season-audit-back-taxes-77c891313f5233366fbe4f6fb5d896e8                                             |\n",
      "|0  |{65e161d47e56c7a1e4ecc798}|jayRIOT       |252         |/r/news/comments/1b3lslv/blockbuster_california_storm_to_deliver_crushing/  |1709268589 |cnn.com         |2024-03-02 00:24:22.398|false  |false   |NULL |NULL     |        |NULL         |news|         |Blockbuster California storm to deliver crushing blow of 10 feet of snow and blizzard conditions|2888       |0.97        |https://www.cnn.com/2024/02/29/weather/california-storm-snow-blizzard-climate/index.html                                                |\n",
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"param1\", \"value1\")\n",
    "    mlflow.log_param(\"param2\", \"value2\")\n",
    "    \n",
    "    try:\n",
    "         # Create a SparkSession\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"F5news\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Load data from MongoDB into a DataFrame\n",
    "        df = spark.read.format(\"mongo\").option(\"uri\", URI).option(\"database\", DATABASE).option(\"collection\", COLLECTION).load()\n",
    "        print(\"Data loaded successfully from MongoDB!\")\n",
    "        \n",
    "        # Show loaded data\n",
    "        df.printSchema()\n",
    "        df.show(5,truncate=False)\n",
    "    except Exception as e:\n",
    "        # Error occurred during data loading or model training\n",
    "        print(\"Error:\", str(e))\n",
    "\n",
    "        # Stop SparkSession\n",
    "        spark.stop()\n",
    "\n",
    "        # End MLflow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out Recent Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Loaded: 4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Filtered Documents: 3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get document initial count\n",
    "print('Documents Loaded:', df.count())\n",
    "\n",
    "# Convert to SQL to ensure proper typing\n",
    "df.createOrReplaceTempView(\"temp\")\n",
    "df = spark.sql(\"SELECT title, upvoteCount, fetchedAt from temp\") \n",
    "\n",
    "# Filter out new posts\n",
    "oneDayAgo = d = datetime.today() - timedelta(days=1)\n",
    "df = df.filter(df.fetchedAt < oneDayAgo)\n",
    "print('Total Filtered Documents:', df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketize by Upvote Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|     bucket|count|\n",
      "+-----------+-----+\n",
      "|      0-999| 3070|\n",
      "|  1000-4999|  520|\n",
      "|  5000-9999|  172|\n",
      "|10000-24999|  101|\n",
      "|25000-49000|   15|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def upvoteCategorizer(upvotes):\n",
    "    if upvotes < 1000:\n",
    "        return \"0-999\"\n",
    "    if upvotes < 5000:\n",
    "        return \"1000-4999\"\n",
    "    if upvotes < 10000:\n",
    "        return \"5000-9999\"\n",
    "    elif upvotes < 25000:\n",
    "        return \"10000-24999\"\n",
    "    elif upvotes < 50000:\n",
    "        return \"25000-49000\"\n",
    "    else: \n",
    "        return \"50000+\"\n",
    "    \n",
    "bucket_udf = udf(upvoteCategorizer, StringType() )\n",
    "df = df.withColumn(\"bucket\", bucket_udf(\"upvoteCount\"))\n",
    "df.groupBy(\"bucket\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Sample Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+-----------+\n",
      "|               title|upvoteCount|           fetchedAt|     bucket|\n",
      "+--------------------+-----------+--------------------+-----------+\n",
      "|Trump Ally and Da...|         82|2024-03-08 19:54:...|      0-999|\n",
      "|Europe starts war...|        162|2024-03-05 19:04:...|      0-999|\n",
      "|US destroyer shoo...|        201|2024-03-06 09:29:...|      0-999|\n",
      "|Trump Says '100 P...|          3|2024-03-10 09:09:...|      0-999|\n",
      "|Zelenskiy Calls O...|       1978|2024-03-04 12:24:...|  1000-4999|\n",
      "|Alabama lawmakers...|          9|2024-03-07 04:49:...|      0-999|\n",
      "|Russian missile s...|       2735|2024-03-07 17:29:...|  1000-4999|\n",
      "|Across the Board,...|          0|2024-03-04 16:19:...|      0-999|\n",
      "|Boeing whistleblo...|        435|2024-03-11 22:44:...|      0-999|\n",
      "|UN Special Repres...|         48|2024-03-04 19:39:...|      0-999|\n",
      "|Smirking and smil...|          6|2024-03-07 13:59:...|      0-999|\n",
      "|Pope Encourages U...|          0|2024-03-10 07:04:...|      0-999|\n",
      "|Outrage over Braz...|         15|2024-03-05 19:29:...|      0-999|\n",
      "|High shower press...|         80|2024-03-10 21:29:...|      0-999|\n",
      "|Two sailors dead ...|         63|2024-03-06 20:24:...|      0-999|\n",
      "|Inside Trump's Ti...|         19|2024-03-09 18:19:...|      0-999|\n",
      "|Pope criticised f...|      23912|2024-03-11 12:14:...|10000-24999|\n",
      "|Zloty returns to ...|         11|2024-03-12 15:39:...|      0-999|\n",
      "|More delays? Supr...|         40|2024-03-04 06:39:...|      0-999|\n",
      "|Russia says it fo...|         23|2024-03-12 16:14:...|      0-999|\n",
      "+--------------------+-----------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_count = 20 # TODO: Calculate proper sample size instead of hardcoded value\n",
    "pandas_random_sample = df.toPandas().sample(n=sample_count) # Convert to pandas dataframe to take sample\n",
    "pyspark_random_sample = spark.createDataFrame(pandas_random_sample) # Convert back to pyspark dataframe\n",
    "pyspark_random_sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression Tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"title\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# Stop Words Remover\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] # TODO: Update stopwords to match dataset\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "# Bag of Words Counter\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=30000, minDF=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"bucket\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the pipeline to training documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|               title|upvoteCount|           fetchedAt|   bucket|               words|            filtered|            features|label|\n",
      "+--------------------+-----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|Ultra-conservativ...|         35|2024-03-01 22:09:...|    0-999|[ultra, conservat...|[ultra, conservat...|(1777,[4,35,494,6...|  0.0|\n",
      "|Joe Biden has rai...|         49|2024-03-01 22:14:...|    0-999|[joe, biden, has,...|[joe, biden, has,...|(1777,[2,5,8,12,1...|  0.0|\n",
      "|Oregon takes mass...|          4|2024-03-01 22:14:...|    0-999|[oregon, takes, m...|[oregon, takes, m...|(1777,[375,426,53...|  0.0|\n",
      "|DC Circuit tosses...|         21|2024-03-01 22:19:...|    0-999|[dc, circuit, tos...|[dc, circuit, tos...|(1777,[0,1,3,4,6,...|  0.0|\n",
      "|Shervin Hajipour:...|         34|2024-03-01 22:19:...|    0-999|[shervin, hajipou...|[shervin, hajipou...|(1777,[0,9,11,14,...|  0.0|\n",
      "|Republicans Who L...|         55|2024-03-01 22:24:...|    0-999|[republicans, who...|[republicans, who...|(1777,[59,67,120,...|  0.0|\n",
      "|Jewish dentist ki...|         35|2024-03-01 22:24:...|    0-999|[jewish, dentist,...|[jewish, dentist,...|(1777,[1,20,100,1...|  0.0|\n",
      "|Trump's threats a...|         40|2024-03-01 22:29:...|    0-999|[trump, s, threat...|[trump, s, threat...|(1777,[2,5,6,9,22...|  0.0|\n",
      "|Only grain ships ...|         29|2024-03-01 22:29:...|    0-999|[only, grain, shi...|[only, grain, shi...|(1777,[4,9,19,77,...|  0.0|\n",
      "|Sweden cuts state...|       3821|2024-03-01 22:39:...|1000-4999|[sweden, cuts, st...|[sweden, cuts, st...|(1777,[4,15,23,25...|  1.0|\n",
      "|Biden says US mil...|         82|2024-03-01 22:44:...|    0-999|[biden, says, us,...|[biden, says, us,...|(1777,[0,8,9,11,1...|  0.0|\n",
      "|Nearly three-quar...|         89|2024-03-01 22:49:...|    0-999|[nearly, three, q...|[nearly, three, q...|(1777,[0,3,29,40,...|  0.0|\n",
      "|Ready, set, fly? ...|          8|2024-03-01 22:54:...|    0-999|[ready, set, fly,...|[ready, set, fly,...|(1777,[1,53,101,1...|  0.0|\n",
      "|What video and ey...|          2|2024-03-01 22:54:...|    0-999|[what, video, and...|[what, video, and...|(1777,[9,14,21,36...|  0.0|\n",
      "|Biden campaign, r...|         47|2024-03-01 23:04:...|    0-999|[biden, campaign,...|[biden, campaign,...|(1777,[5,8,15,32,...|  0.0|\n",
      "|Biden announces U...|       1460|2024-03-01 23:09:...|1000-4999|[biden, announces...|[biden, announces...|(1777,[2,8,17,36,...|  1.0|\n",
      "|New York AG Letit...|         46|2024-03-01 23:14:...|    0-999|[new, york, ag, l...|[new, york, ag, l...|(1777,[2,18,22,91...|  0.0|\n",
      "|Lesbian senator’s...|         65|2024-03-01 23:14:...|    0-999|[lesbian, senator...|[lesbian, senator...|(1777,[2,7,35,57,...|  0.0|\n",
      "|UK and US accused...|          8|2024-03-01 23:14:...|    0-999|[uk, and, us, acc...|[uk, and, us, acc...|(1777,[3,9,14,46,...|  0.0|\n",
      "|IVF fight comes t...|         19|2024-03-01 23:19:...|    0-999|[ivf, fight, come...|[ivf, fight, come...|(1777,[0,168,298,...|  0.0|\n",
      "|Undocumented immi...|          0|2024-03-01 23:19:...|    0-999|[undocumented, im...|[undocumented, im...|(1777,[0,1,6,22,6...|  0.0|\n",
      "|Move to split up ...|          7|2024-03-01 23:19:...|    0-999|[move, to, split,...|[move, to, split,...|(1777,[0,1,11,56,...|  0.0|\n",
      "|Carol Stream poli...|         41|2024-03-01 23:24:...|    0-999|[carol, stream, p...|[carol, stream, p...|(1777,[3,28,93,10...|  0.0|\n",
      "|Fox News ‘Migrant...|         63|2024-03-01 23:29:...|    0-999|[fox, news, migra...|[fox, news, migra...|(1777,[3,6,12,85,...|  0.0|\n",
      "|Virginia councilo...|       1056|2024-03-01 23:29:...|1000-4999|[virginia, counci...|[virginia, counci...|(1777,[4,312,459,...|  1.0|\n",
      "+--------------------+-----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 23:19:57 WARN Instrumentation: [b736b51f] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/03/13 23:20:04 WARN Instrumentation: [b736b51f] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 4779.478962694921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(testData)\n",
    "rmse = predictions.selectExpr(\"sqrt(avg(pow(upvoteCount - prediction, 2))) as RMSE\").collect()[0][\"RMSE\"]\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data:\", rmse) # TODO: Determine output label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Final Model Metrics to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f29708739d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics\n",
    "mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "# Log trained model\n",
    "mlflow.spark.log_model(lr_model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Out Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkSession\n",
    "spark.stop()\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
